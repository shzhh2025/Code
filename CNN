%% CNN 5-Fold Cross Validation
% Author: Zhonghua Shen
% Date: 2025-09-05
% Description: CNN for bacterial classification

%% -------------------------------
% CNN
%% -------------------------------

% Open the Data
loadedData = load('cvIndices.mat');
X_train = loadedData.X_train;
y_train = loadedData.y_train;
X_validation = loadedData.X_validation;
y_validation = loadedData.y_validation;
feature_names = loadedData.feature_names;

% Generate 5-fold cross validation splits
cv = cvpartition(y_train, 'KFold', 5);

% Data preprocessing 
X_train = reshape(X_train', [1288, 1, 1, size(X_train, 1)]);
X_validation = reshape(X_validation', [1288, 1, 1, size(X_validation, 1)]);

% CNN
layers = [
imageInputLayer([1288 1 1], 'Name', 'input') 
convolution2dLayer([5 1], 10, 'Padding', 'same', 'Name', 'conv1')
reluLayer('Name', 'relu1')
maxPooling2dLayer([2 1], 'Stride', [2 1], 'Name', 'maxpool1')
convolution2dLayer([3 1], 20, 'Padding', 'same', 'Name', 'conv2')
reluLayer('Name', 'relu2')
maxPooling2dLayer([2 1], 'Stride', [2 1], 'Name', 'maxpool2')
convolution2dLayer([3 1], 40, 'Padding', 'same', 'Name', 'conv3')
reluLayer('Name', 'relu3')
flattenLayer('Name', 'flatten')
dropoutLayer(0.5, 'Name', 'dropout')
fullyConnectedLayer(256, 'Name', 'fc1')
reluLayer('Name', 'relu4')
fullyConnectedLayer(64, 'Name', 'fc2')
reluLayer('Name', 'relu5')
fullyConnectedLayer(12, 'Name', 'fc3') 
softmaxLayer('Name', 'softmax')
classificationLayer('Name', 'output')
];

% Storage loss and accuracy
numFolds = cv.NumTestSets;
maxEpochs = 20; 
miniBatchSize = 16; 
trainingLossAll = cell(numFolds, 1); 
validationLossAll = cell(numFolds, 1); 
trainingAccuracyAll = cell(numFolds, 1); 
validationAccuracyAll = cell(numFolds, 1); 

% Cross-validation
for i = 1:numFolds
% Extract training and test set data
trainIdx = cv.training(i); 
testIdx = cv.test(i);
X_train_fold = X_train(:,:,:,trainIdx); 
y_train_fold = categorical(y_train(trainIdx)); 
X_test_fold = X_train(:,:,:,testIdx); 
y_test_fold = categorical(y_train(testIdx)); 

% Define
options = trainingOptions('adam', ...
'MaxEpochs', maxEpochs, ... 
'MiniBatchSize', miniBatchSize, ... 
'ValidationData', {X_test_fold, y_test_fold}, ... 
'ValidationFrequency', 1, ... 
'Verbose', false, ...
'Plots', 'training-progress');

% Train
[net, info] = trainNetwork(X_train_fold, y_train_fold, layers, options);

% Data save
trainingLossAll{i} = info.TrainingLoss; 
validationLossAll{i} = info.ValidationLoss; 
trainingAccuracyAll{i} = info.TrainingAccuracy; 
validationAccuracyAll{i} = info.ValidationAccuracy; 
end

% Average
meanTrainingLoss = mean(cat(1, trainingLossAll{:}), 1);
meanValidationLoss = mean(cat(1, validationLossAll{:}), 1);
meanTrainingAccuracy = mean(cat(1, trainingAccuracyAll{:}), 1);
meanValidationAccuracy = mean(cat(1, validationAccuracyAll{:}), 1);

% Plot loss cover
figure;
plot(meanTrainingLoss, 'b', 'DisplayName', 'Training Loss');
hold on;
plot(meanValidationLoss, 'r', 'DisplayName', 'Validation Loss');
legend;
title('Loss Curve');
xlabel('Epoch');
ylabel('Loss');
xlim([0 6080]); 
xticks(0:304:6080); 
hold off;

% Plot accuracy cover
figure;
plot(meanTrainingAccuracy, 'b', 'DisplayName', 'Training Accuracy');
hold on;
plot(meanValidationAccuracy, 'r', 'DisplayName', 'Validation Accuracy');
legend;
title('Accuracy Curve');
xlabel('Epoch');
ylabel('Accuracy');
xlim([0 6080]); 
xticks(0:304:6080); 
hold off;

%Heatmap visualization
sampleIndex = 1; 
sampleImage = X_validation(:,:,:,sampleIndex);
conv1Activations = activations(net, sampleImage, 'conv1');
conv2Activations = activations(net, sampleImage, 'conv2');
conv3Activations = activations(net, sampleImage, 'conv3');
% Conv1
figure;
for i = 1:size(conv1Activations, 3)
subplot(2, 5, i);
imagesc(conv1Activations(:,:,i));
colormap('hot'); 
colorbar; 
title(['Conv1', num2str(i)]);
end
sgtitle('Conv1 Layer Feature Maps (Heatmaps)');
% Conv2
figure;
for i = 1:size(conv2Activations, 3)
subplot(4, 5, i);
imagesc(conv2Activations(:,:,i));
colormap('hot'); 
colorbar; 
title(['Conv2', num2str(i)]);
end
sgtitle('Conv2 Layer Feature Maps (Heatmaps)');
% Conv3
figure;
for i = 1:size(conv3Activations, 3)
subplot(5, 8, i);
imagesc(conv3Activations(:,:,i));
colormap('hot'); 
colorbar; 
title(['Conv3 - Filter ', num2str(i)]);
end
sgtitle('Conv3 Layer Feature Maps (Heatmaps)');

% PCA visualization
numSamplesPerClass = 20;
selectedIndices = [];
categories = unique(y_validation);

for i = 1:numel(categories)
    classIndices = find(y_validation == categories(i));
    selectedIndices = [selectedIndices; classIndices(1:numSamplesPerClass)];
end
% Selected samples
XSelected = X_validation(:,:,:,selectedIndices);
YSelected = y_validation(selectedIndices);
colorIndices = findgroups(YSelected);
% Pre-CNN
originalFeatures = reshape(XSelected, size(XSelected, 1), [])';
[~, scoreOriginal, ~, ~, explainedOriginal] = pca(originalFeatures);
X_pcaOriginal = scoreOriginal(:, 1:2);
% pre-CNN visualization
figure;
scatter(X_pcaOriginal(:,1), X_pcaOriginal(:,2), 50, colorIndices, 'filled');
xlabel('Principal Component 1');
ylabel('Principal Component 2');
title('2D PCA of Original Features');
grid on;
colorbar;
colormap(jet(numel(categories)));
legend(categories, 'Location', 'best');
% 'conv1', 'conv2', 'conv3', 'flatten' visualization
layersToVisualize = {'conv1', 'conv2', 'conv3', 'flatten'};

for layerIndex = 1:numel(layersToVisualize)
    layer = layersToVisualize{layerIndex};
    
    if strcmp(layer, 'flatten')
        features = activations(net, XSelected, layer, 'OutputAs', 'rows');
    else
        convActivations = activations(net, XSelected, layer);
        features = reshape(convActivations, size(convActivations,1)*size(convActivations,2)*size(convActivations,3), [])';
    end
   [~, score, ~, ~, explained] = pca(features);
    X_pca = score(:,1:2);
% plot
figure;
    scatter(X_pca(:,1), X_pca(:,2), 50, colorIndices, 'filled');
    xlabel('Principal Component 1');
    ylabel('Principal Component 2');
    title(['2D PCA of ', layer, ' Features']);
    grid on;
    colorbar;
    colormap(jet(numel(categories)));
        try
        legend(categories, 'Location', 'best');
    catch
        warning('Legend could not be created for layer: %s', layer);
    end
end

%Save data and net
y_train = grp2idx(y_train);
y_validation = grp2idx(y_validation);
save('path/model.mat', 'net');
save('path/data.mat', 'net', 'X_train', 'y_train', 'X_validation', 'y_validation','feature_names');


% evaluated in independent validation set 
y_pred_validation = classify(net, X_validation);

% Accuracy
validation_accuracy = sum(y_pred_validation == y_validation) / numel(y_validation);
disp(['Validation Accuracy: ', num2str(validation_accuracy * 100), '%']);
% Confusion Matrix
figure;
confusionchart(y_validation, y_pred_validation);
title('Confusion Matrix (Validation Set)');
% Recall, Precision,and F1 score
unique_labels = unique(y_validation);
recall_validation = zeros(length(unique_labels), 1);
precision_validation = zeros(length(unique_labels), 1);
f1_score_validation = zeros(length(unique_labels), 1);
y_train_categorical = categorical(y_train);
y_train=y_train_categorical;
y_validation = categorical(y_validation);

% 验证集预测
y_pred_validation = classify(net, X_validation);
% 计算验证集上的指标
accuracyValidation = sum(y_pred_validation == y_validation) / numel(y_validation);
disp(['Validation accuracy: ', num2str(accuracyValidation)]);


# Calculate SHAP value
import numpy as np
import shap
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from scipy.io import loadmat
file_path = 'Path/'
os.makedirs(file_path, exist_ok=True)
data_file_path = 'Path/data.mat'
shap_values_path = 'Path/shap_values.npy'
mat = loadmat(data_file_path)
X_train = mat['X_train']
y_train = mat['y_train'].ravel()
X_test = mat['X_validation']
y_test = mat['y_validation'].ravel()
# Chang X_train and X_test to shap (sample, 1288, 1, 1)
X_train = np.transpose(X_train, (3, 0, 1, 2))
X_test = np.transpose(X_test, (3, 0, 1, 2))
# One-hot encode labels, 
y_train_adjusted = y_train - 1
y_test_adjusted = y_test - 1
# One-hot encode labels
num_classes = len(np.unique(y_train_adjusted))
y_train_one_hot = to_categorical(y_train_adjusted, num_classes)
y_test_one_hot = to_categorical(y_test_adjusted, num_classes)
# Build CNN model
model = Sequential([
Conv2D(10, (5, 1), activation='relu', padding='same', input_shape=(1288, 1, 1)),
MaxPooling2D(pool_size=(2, 1), strides=(2, 1)),
Conv2D(20, (5, 1), activation='relu', padding='same'),
MaxPooling2D(pool_size=(2, 1), strides=(2, 1)),
Conv2D(40, (3, 1), activation='relu', padding='same'),
Flatten(),
Dropout(0.5),
Dense(256, activation='relu'),
Dense(64, activation='relu'),
Dense(num_classes, activation='softmax')
])
# Compile model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# Train model
model.fit(X_train, y_train_one_hot, epochs=20, batch_size=16, validation_data=(X_test, y_test_one_hot))
# Compute SHAP values using Deep SHAP
background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)] # background data
explainer = shap.DeepExplainer(model, background)
shap_values = explainer.shap_values(X_test)
# Save SHAP values to .npy file
np.save(shap_values_path, shap_values)
print(type(shap_values))
print(len(shap_values)) 

% SHAP visualization
python_script_path = 'path';
shap_values_path = 'path';
% Running a Python script
status = system(['"', python_executable, '" "', python_script_path, '"']);
% Reading .npy files
shap_values_py = py.numpy.load(shap_values_path);
% Convert to MATLAB array
shap_values = double(shap_values_py);
% Calculate the mean absolute SHAP value for each feature
mean_abs_shap_values = mean(abs(shap_values), [1]);
% Top 50
[~, sorted_idx] = sort(mean_abs_shap_values, 'descend');
top_50_idx = sorted_idx(1:50);
% Top 50 name
top_50_feature_names = feature_names(top_50_idx);
top_50_idx = flip(top_50_idx);
top_50_feature_names = flip(top_50_feature_names);
% Figure
figure;
hold on;
colors = jet(length(top_50_idx));
for j = 1:length(top_50_idx)
feature_idx = top_50_idx(j);
scatter(shap_values(:, feature_idx), repmat(j, size(shap_values, 1), 1), 15, shap_values(:, feature_idx), 'filled');
end
hold off;

set(gca, 'YTick', 1:50);
set(gca, 'YTickLabel', top_50_feature_names);
xlabel('SHAP Value');
ylabel('Feature');
title('Top 50 Features Based on SHAP Values');
colormap jet;
colorbar;
